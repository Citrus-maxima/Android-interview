# 内存占用指标

VSS >= RSS >= PSS >= USS

- VSS - Virtual Set Size 虚拟耗用内存（包含共享库占用的内存）

- RSS - Resident Set Size 实际使用物理内存（包含共享库占用的内存）

- PSS - Proportional Set Size 实际使用的物理内存（比例分配共享库占用的内存）

- USS - Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存）

![image](https://github.com/user-attachments/assets/26e97a0f-6e8b-4b9a-b218-dc4b2b357ef2)

VSS用处不大，其大小还包括了可能不在RAM中的内存（比如虽然malloc分配了空间，但尚未写入）。VSS很少被用于判断一个进程的真实内存使用量。

RSS不能准确地反映单进程的内存占用情况。

系统中所有进程的PSS相加，刚好反映了系统总共占用的内存。

USS反映了运行一个特定的进程真实的边际成本。当一个进程被销毁后，USS是真实返回给系统的内存。当进程中存在一个可疑的内存泄露时，USS是最佳观察数据。

# 内存分析命令

1. `dumpsys meminfo`

   显示内存使用情况，例如：   

```shell
Applications Memory Usage (in Kilobytes):
Uptime: 1006439 Realtime: 1006439

Total RSS by process:  // 以进程的RSS从大到小依次排序显示，每行显示一个进程
  1,045,512K: com.android.systemui (pid 4861)
    689,956K: system (pid 3027)
    353,492K: com.android.settings (pid 8170 / activities)
    ...
    
Total RSS by OOM adjustment:  // 以oom来划分，会详细列举所有的类别的进程
  2,319,928K: Native  // 只展示几个native进程，其他类别省略
        316,300K: vendor.qti.camera.provider-service_64 (pid 1637)
        194,320K: surfaceflinger (pid 1773)
        161,944K: zygote64 (pid 1384)
        ...   
  689,956K: System
  3,606,252K: Persistent
  164,296K: Persistent Service
  791,240K: Foreground
  2,615,068K: Visible
  1,006,688K: Perceptible
  252,448K: A Services
  353,492K: Previous
  241,764K: B Services
  6,819,940K: Cached
  
Total RSS by category:
  4,515,912K: .so mmap
  3,161,856K: .jar mmap
  ...
  
Total PSS by process:  // 和RSS的类似，此处省略
Total PSS by OOM adjustment:  // 此处省略
Total PSS by category:  // 此处省略

// 整体情况
Total RAM: 11,478,156K (status normal)
 Free RAM: 5,321,917K (  756,665K cached pss + 4,023,404K cached kernel +   541,848K free)
DMA-BUF:   264,576K (   70,136K mapped +   194,440K unmapped)
DMA-BUF Heaps:   264,576K
DMA-BUF Heaps pool:   773,240K
      GPU:   485,188K
 Used RAM: 5,174,909K (3,578,269K used pss + 1,596,640K kernel)
 Lost RAM:   993,790K
     ZRAM:     8,172K physical used for    23,040K in swap (8,388,604K total swap)
   Tuning: 256 (large 512), oom   322,560K, restore limit   107,520K (high-end-gfx)
```

| 一级标签           | 二级标签          | 含义                                                         | 计算方式                                                     |
| ------------------ | ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Total RAM          |                   | 当前系统的所有内存大小。一般并不等于机器的物理内存大小。物理内存 - kernel reserved = 系统实际内存总和 | /proc/meminfo的"MemTotal"                                    |
| Free RAM           | 1 + 2 + 3         |                                                              |                                                              |
|                    | 1. cached pss     | 一般都是切到后台的进程，表示可以随时回收                     | Total PSS by OOM adjustment中子模块为 cached 的合计值        |
|                    | 2. cached kernel  |                                                              | /proc/meminfo中的“Buffers:”+“Cached:”+“KReclaimable:”，如果“KReclaimable:”项为0则用"SReclaimable:" |
|                    | 3. free           |                                                              | /proc/meminfo中的"MemFree:”                                  |
| DMA-BUF            | 1 + 2             |                                                              | 将/sys/kernel/dmabuf/buffers路径下每个目录下的size累加       |
|                    | 1. mapped         |                                                              | 遍历每个/proc/$pid/maps文件，对于一个maps文件，遍历其每一行，将行尾有name的行的endaddr（第二串数字）和startaddr（第一串数字）相减作为size进行累加得到一个maps文件的mappedsize，最后将所有pid的mapedsize/1024进行累加 |
|                    | 2. unmapped       |                                                              | DMA-BUF total - mapped部分                                   |
| DMA-BUF Heaps      |                   |                                                              | 根据/dev/dma_heap路径下的文件名，遍历累加/sys/kernel/dmabuf/buffers/$@/exporter_name中的值与之对应的size之和 |
| DMA-BUF Heaps pool |                   |                                                              | /sys/kernel/dma_heap/total_pools_kb                          |
| GPU                |                   |                                                              | /sys/fs/bpf/map_gpuMem_gpu_mem_total_map                     |
| Used RAM           | 1 + 2             |                                                              |                                                              |
|                    | 1. used pss       |                                                              | (所有/proc/$pid/maps中pss+swappss) - (OOM分类下cachedPss) - (category分类下的EGL和GL )+ (DMA-BUF的mapped部分) |
|                    | 2. kernel         |                                                              | "Shmem:"+"SUnreclaim:"+"VmallocUsed:"+"PageTables:"+DMA中unmap部分+GPU中private部分。其实还会加上!Debug.isVmapStack()?"KernelStack:":0，但除了初始化第一次调用之外，该值都为0 |
| Lost RAM           |                   |                                                              | "Total RAM: "-（/proc/$@pid/smaps文件中纯Pss数据累加） -Free RAM的free部分- ("Buffers:"+("KReclaimable:"==0?"SReclaimable:":"KReclaimable:")+"Cached:"-"Mapped:")- Used RAM的kernel部分 - ZRAM的physical used部分 |
| ZRAM               | physical used for |                                                              | /sys/block/zram$/mm_stat文件的第三列数字，如果mm_stat不存在则读取mem_used_total的值 |
|                    | in swap           |                                                              | "SwapTotal:"-"SwapFree:"                                     |
|                    | total swap        |                                                              | "SwapTotal:"                                                 |
| Tuning             |                   | 单个应用可用最大内存                                         | getprop dalvik.vm.heapgrowthlimit                            |
|                    | large             | 表示单个进程可用的最大内存，但如果存在heapgrowthlimit参数，则以heapgrowthlimit为准 | getprop dalvik.vm.heapsize                                   |
|                    | oom               |                                                              | ProcessList.CACHED_APP_MAX_ADJ(999)与mOomAdj（0,100,200,250,900,950）数组中挨个比较，mOomMinFree[index]值，否则返回mOomMinFree[mOomAdj.length-1]的值 |
|                    | restore limit     |                                                              | $oom/3                                                       |
|                    | high-end-gfx      |                                                              |                                                              |

2. `procrank`

   获取所有进程的内存使用的排行榜，排行是以Pss的大小而排序。procrank命令比dumpsys meminfo命令，能输出更详细的VSS/RSS/PSS/USS内存指标。

   最后一行输出6个指标：total、free、buffers、cached、shmem、slab

3. `cat /proc/meminfo`

   查看更加详细的内存信息

   ```shell
   MemTotal:       11478156 kB  //RAM可用的总大小 (即物理总内存减去系统预留和内核二进制代码大小)
   MemFree:         1019444 kB  //RAM未使用的大小
   MemAvailable:    5515228 kB
   Buffers:            4000 kB  //用于文件缓冲
   Cached:          4497868 kB  //用于高速缓存
   SwapCached:         2244 kB  //用于swap缓存
   Active:          2676120 kB  //活跃使用状态，记录最近使用过的内存，通常不回收用于其它目的。Active = Active(anon) + Active(file)
   Inactive:        3963576 kB  //非活跃使用状态，记录最近并没有使用过的内存，能够被回收用于其他目的。Inactive = Inactive(anon) + Inactive(file)
   Active(anon):    1605244 kB
   Inactive(anon):   937572 kB
   Active(file):    1070876 kB
   Inactive(file):  3026004 kB
   Unevictable:      393024 kB
   Mlocked:          135928 kB
   SwapTotal:       8388604 kB  //swap总大小
   SwapFree:        8177660 kB  //swap可用大小
   Dirty:               144 kB  //等待往磁盘回写的大小
   Writeback:             0 kB  //正在往磁盘回写的大小
   AnonPages:       2529052 kB  //匿名页，用户空间的页表，没有对应的文件
   Mapped:          1484408 kB  //文件通过mmap分配的内存，用于map设备、文件或者库
   Shmem:            277772 kB
   KReclaimable:     810424 kB
   Slab:            1080204 kB  //kernel数据结构的缓存大小，Slab=SReclaimable+SUnreclaim
   SReclaimable:     488968 kB  //可回收的slab的大小
   SUnreclaim:       591236 kB  //不可回收slab的大小
   KernelStack:       79984 kB
   ShadowCallStack:       0 kB
   PageTables:       177020 kB  //以最低的页表级
   SecPageTables:         0 kB
   NFS_Unstable:          0 kB  //不稳定页表的大小
   Bounce:                0 kB
   WritebackTmp:          0 kB
   CommitLimit:    14127680 kB
   Committed_AS:   151643692 kB  //评估完成的工作量，代表最糟糕case下的值，该值也包含swap内存
   VmallocTotal:   259653632 kB  //总分配的虚拟地址空间
   VmallocUsed:      347408 kB  //已使用的虚拟地址空间
   VmallocChunk:          0 kB  //虚拟地址空间可用的最大连续内存块
   Percpu:            26560 kB
   AnonHugePages:         0 kB
   ShmemHugePages:        0 kB
   ShmemPmdMapped:        0 kB
   FileHugePages:         0 kB
   FilePmdMapped:         0 kB
   CmaTotal:         655360 kB
   CmaFree:          565748 kB
   ```
   cache和buffer也是系统可以使用的内存。所以系统总的可用内存为 MemFree + Buffers +Cached

4. `free`
    
    ```shell
            total        used        free      shared     buffers
   Mem:      11753631744 10733977600  1019654144   285769728     4096000
   -/+ buffers/cache:    10729881600  1023750144
   Swap:      8589930496   216006656  8373923840
    ```
   对于Mem行，存在的公式关系： total = used + free;

   对于-/+ buffers行： 1760936 = 1836040 - 75104(buffers); 1096096 = 1020992 + 75104(buffers);

5. `showmap`

   用法：`showmap -a [pid]`。主功能：用于查看虚拟地址区域的内存情况，该命令的输出每一行代表一个虚拟地址区域(vm area)。功能与`cat /proc/[pid]/maps`基本一致。

   start addr和end addr:分别代表进程空间的起止虚拟地址；

   virtual size/ RSS /PSS；

   shared clean：代表多个进程的虚拟地址可指向这块物理空间，即有多少个进程共享这个库；

   shared: 共享数据

   private: 该进程私有数据

   clean: 干净数据，是指该内存数据与disk数据一致，当内存紧张时，可直接释放内存，不需要回写到disk

   dirty: 脏数据，与disk数据不一致，需要先回写到disk，才能被释放。

6. `vmstat`

   主功能：不仅可以查看内存情况，还可以查看进程运行队列、系统切换、CPU时间占比等情况。vmstat的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数。

   ```shell
   procs ------------memory------------ ---swap-- -----io---- --system- ----cpu----
    r  b    swpd    free   buff   cache   si   so    bi    bo   in   cs us sy id wa
    1  0  210944  939812   4004 5002984    1    9   248   257   80  110  1  2 97  0
    0  0  210944  939560   4004 5000920    0    0     0  1782  409  518  0  2 98  0
    0  0  210944  939560   4004 5000920    0    0     0     0  318  427  0  1 98  0
    1  0  210688  984280   3860 4874688   38    0     0  1579 12681 16422 10 28 61 0
    ```

   参数列总共15个参数，分为4大类：

   procs(进程)
   
      r: Running队列中进程数量。如果运行队列过大，表示CPU很繁忙，一般会造成CPU使用率很高。

      b: IO wait的进程数量。

   memory(内存)

      swpd: 

      free：空闲的物理内存的大小

      buff: 文件缓冲

      cache: 高速缓存

   swap

      si: 每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了。

      so：每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。

   io

      bi: 块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte。

      bo：块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。

   system(系统)

      in: 每秒的中断次数(包括时钟中断)

      cs: 每秒上下文切换的次数
 
   cpu(处理器)

      us: user time

      ni: nice time

      sy: system time

      id: idle time

      wa: iowait time

      ir: interrupt time

   
# 内存问题表现形式

内存溢出(out of memory):是指程序在申请内存时，没有足够的内存空间供其使用。

内存泄漏(memory leak):是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄漏危害可以忽略，但内存泄漏堆积后果很严重，无论多少内存，迟早会被占光。表现：可用内存逐渐减少、频繁GC。

memory leak最终会导致out of memory。 

内存抖动(Memory Churn)：在程序需要对象的时候，在堆当中分配出来一块空间，使用完毕以后， GC帮我们清理掉这片内存空间，如果频繁地一直持续上述操作，就会引起内存抖动。表现：锯齿状、GC频繁导致卡顿。

## 内存溢出

### 原因：

1. Java堆内存溢出

2. 无足够连续内存空间

3. fd数量超出限制（1024，ulimit -a查看）

4. 线程数量超出限制（1024）

5. 虚拟内存不足（使用多进程，如大图片放到一个单独的进程）

/system/build.prop文件中：dalvik.vm.heapstartsize是app启动的初始分配内存，dalvik.vm.heapgrowthlimit是app最大内存限制，dalvik.vm.heapsize是开启largeHeap="true"的最大内存限制。

## 内存泄漏

### 原因：

- **单例造成的内存泄漏**

原因：

不正确使用单例模式，也会引起内存泄漏单例对象在初始化后将在JVM的整个生命周期存在（以静态变量方式），如果单例对象持有外部对象的引用，那么这个外部对象就会一直占用着内存，可能导致内存泄漏（取决于这外部对象是否一致有用）。 

解决方案：

创建单例时不能使用Activity的Context，要使用Application的Context。

- **非静态内部类创建静态实例造成的内存泄漏（使用静态内部类）**
  
- **handler造成的内存泄漏**

Handler内存泄露的原因通常与Handler如何持有和使用Context（如Activity）的引用有关。

原因：

（1）Handler持有Activity的引用：当Handler作为Activity的非静态内部类时，它会默认持有Activity的引用。如果Handler被声明为静态的或者在一个长生命周期的对象（如单例、静态变量、线程等）中持有，那么在Activity销毁后，由于Handler仍然持有Activity的引用，这将阻止Activity被垃圾回收器回收，从而导致内存泄露。

（2）MessageQueue中的消息：当Activity销毁时，如果Handler中还有未处理的消息在MessageQueue中等待处理，这些消息会持有Handler的引用，进而持有Activity的引用，导致Activity无法被回收。

解决方案：

（1）使Handler成为静态的：通过将Handler声明为静态的，可以确保Handler的生命周期不依赖于Activity。但是，这样做需要手动管理对Activity的引用，避免潜在的空指针异常。

（2）在Activity销毁时移除消息和回调：在Activity的onDestroy()方法中，确保移除所有与Handler相关的回调和消息。这可以通过调用Handler的removeCallbacks()和removeMessages()方法实现。

（3）使用WeakReference：可以使用WeakReference来持有Activity的引用，这样当Activity不再需要时，它可以被垃圾回收器回收。但是，使用WeakReference需要谨慎处理，因为当引用变为null时，需要确保不会再次使用它。

总之，为了避免Handler导致的内存泄露，需要仔细管理Handler和Activity之间的引用关系，并确保在适当的时机释放这些引用。

- **线程造成的内存泄漏**

原因：

线程生命周期不可控，比如线程是Activity的内部类，则线程对象中保存了Activity的一个引用，当线程的run函数耗时较长没有结束时，线程对象是不会被销毁的，因此它所引用的老的Activity就出现了内存泄漏问题。

解决方案：

1.简化线程run函数执行的任务，使他在Activity生命周期结束前，任务运行完。

2.为Thread增加撤销机制，当Activity生命周期结束时，将Thread的耗时任务撤销。
        
- **webview造成的内存泄漏**

解决方案：

单独放一个进程，用完后killProcess。

- **不良代码**

如：Bitmap使用完不调用recycle()。Bitmap 对象在不使用时，我们应该先调用recycle（）释放内存，然后才置空，因为加载bitmap对象的内存空间，一部分是java的，一部分是c的（因为Bitmap分配的底层是通过jni调用的，Android的Bitmap底层是使用skia图形库实现，skia是用c实现的）。这个recycle（）函数就是针对c部分的内存释放。

## 内存抖动

# 内存分析工具

## 1. LeakCanary

## 2. Memory Profiler

## 3. MAT
